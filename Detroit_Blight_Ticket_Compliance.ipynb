{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31989661",
   "metadata": {},
   "source": [
    "# The problem and the dataset for this notebook are taken from \"Detroit Blight Ticket Compliance\" competition on Kaggle which is also available on coursera. (More details can be found in the PDF file in the same folder as this jupyter notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a295e92",
   "metadata": {},
   "source": [
    "# Importing the necessary packages/libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c5de074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e918ccdd",
   "metadata": {},
   "source": [
    "# Defining functions for converting a date string to a python datetime object, finding the day of year for ticket issue date and finding gap between ticket issue date and hearing date. Also, functions for finding latitude and longitude using ticket id are defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71f7f22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\16178\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def split_string(x) :\n",
    "    if not isinstance(x, str) :\n",
    "        return x\n",
    "    return x.split()[0]\n",
    "def date_time_object(x) :\n",
    "    if not isinstance(x, str) :\n",
    "        return x\n",
    "    return datetime.date(int(x.split('-')[0]),int(x.split('-')[1]),int(x.split('-')[2]))\n",
    "def find_day(x) :\n",
    "    return (x - datetime.date(x.year, 1, 1)).days + 1\n",
    "def find_gap(x) :\n",
    "    if not isinstance(x['hearing_date'], datetime.date) :\n",
    "        return np.nan\n",
    "    return (x['hearing_date']-x['ticket_issued_date']).days\n",
    "def find_lat(x) :\n",
    "    return latlons_dict[addresses_dict[x]][0]\n",
    "def find_lon(x) :\n",
    "    return latlons_dict[addresses_dict[x]][1] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5015f6d9",
   "metadata": {},
   "source": [
    "# Choosing the relevant columns from provided dataset, dropping any rows containing infinity or NA and partitioning dataset into feature vectors and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba24bdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\16178\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (11,12,31) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv', encoding='cp1252')\n",
    "# Only certian columns in available training dataset are being retained. Those columns which provide information that is\n",
    "# likely to generalize are retained. Columns that are missing in test data must be discarded in training data too.\n",
    "train_df = train_df[['ticket_id', 'agency_name', 'city', 'state', 'country', 'ticket_issued_date', 'hearing_date',\n",
    "       'violation_code', 'disposition', 'fine_amount', 'admin_fee', 'state_fee', 'late_fee', 'discount_amount',\n",
    "       'clean_up_cost', 'judgment_amount', 'compliance']]\n",
    "# Dropping any rows containing NA\n",
    "train_df = train_df.dropna()\n",
    "train_df = train_df[(train_df['compliance'] == 1) | (train_df['compliance'] == 0)]\n",
    "# Paritioning the data into feature vectors and labels\n",
    "X_train = train_df.drop('compliance', axis=1)\n",
    "y_train = train_df['compliance']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a73c7c1",
   "metadata": {},
   "source": [
    "# Obtaining new features using the provided features in dataset and obtaining one-hot vectors for columns of category type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23dcba56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\16178\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Replacing different ways of writing Detroit with one form\n",
    "X_train['city'] = X_train['city'].replace({'detroit':'Detroit', 'det':'Detroit', 'Det':'Detroit', 'DETROIT':'Detroit',\n",
    "                                           'DEt':'Detroit', 'Det.':'Detroit'})\n",
    "X_train['ticket_issued_date'] = X_train['ticket_issued_date'].apply(lambda x: date_time_object(x.split()[0]))\n",
    "X_train['ticket_issued_day'] = X_train['ticket_issued_date'].apply(lambda x: find_day(x))\n",
    "X_train['hearing_date'] = X_train['hearing_date'].apply(lambda x: split_string(x))\n",
    "X_train['hearing_date'] = X_train['hearing_date'].apply(lambda x: date_time_object(x))\n",
    "# Finding gap between ticket issue date and hearing date\n",
    "X_train['gap_days'] = X_train.apply(lambda x: find_gap(x), axis = 'columns')\n",
    "# Finding if city in mailing address is same as location of violation site\n",
    "X_train['city_flag'] = (X_train['city'] == 'Detroit')*1.0\n",
    "# Finding if state in mailing address is same as location of violation site\n",
    "X_train['state_flag'] = (X_train['state'] == 'MI')*1.0\n",
    "# Finding if country in mailing address is same as location of violation site\n",
    "X_train['country_flag'] = (X_train['country'] == 'USA')*1.0\n",
    "addresses_df = pd.read_csv('addresses.csv')\n",
    "latlons_df = pd.read_csv('latlons.csv')\n",
    "latlons_df['latlon'] = latlons_df.apply(lambda x: (x['lat'],x['lon']), axis = 'columns')\n",
    "addresses_dict = dict(zip(addresses_df.ticket_id, addresses_df.address))\n",
    "latlons_dict = dict(zip(latlons_df.address, latlons_df.latlon))\n",
    "# Finding latitude of violation site using ticket id\n",
    "X_train['lat'] =  X_train['ticket_id'].apply(lambda x: find_lat(x))\n",
    "# Finding longitude of violation site using ticket id\n",
    "X_train['lon'] =  X_train['ticket_id'].apply(lambda x: find_lon(x))\n",
    "# Violation codes that have frequency less than 1% are being replaced by 'Other'\n",
    "X_train['violation_code'] = X_train['violation_code'].mask(X_train['violation_code'].map(X_train['violation_code'].value_counts(normalize=True)) < 0.01, 'Other')\n",
    "X_train = X_train[['agency_name', 'violation_code', 'disposition', 'fine_amount', 'late_fee', 'discount_amount',\n",
    "                   'judgment_amount', 'ticket_issued_day', 'gap_days', 'city_flag', 'state_flag', 'country_flag',\n",
    "                   'lat', 'lon']]\n",
    "# Obtaining one-hot vectors for data columns of type category\n",
    "X_train = pd.get_dummies(X_train, columns = ['agency_name', 'violation_code', 'disposition'])\n",
    "X_y_train = pd.concat([X_train, y_train], axis=1, join='inner')\n",
    "# Dropping rows containing infinite and NA values\n",
    "X_y_train = X_y_train.replace([np.inf, -np.inf], np.nan).dropna(axis=0)\n",
    "y_train = X_y_train['compliance']\n",
    "X_train = X_y_train.drop(['compliance'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa48d3a0",
   "metadata": {},
   "source": [
    "# Training a random forest classifier and optimizing hyper-parameters using grid search. Area under ROC curve is used as evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b045f8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\16178\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve is 0.8113132510880079\n"
     ]
    }
   ],
   "source": [
    "parameters = {'n_estimators': [100, 150], 'max_depth':[4, 5]}\n",
    "clf_dummy = RandomForestClassifier()\n",
    "# Performing a grid search to find optimum parameters for random forest classifier. Area under ROC curve is used as metric.\n",
    "clf = GridSearchCV(clf_dummy, parameters, scoring = 'roc_auc')\n",
    "X_cv = X_train[:143610]\n",
    "X_test = X_train[143610:]\n",
    "y_cv = y_train[:143610]\n",
    "y_test = y_train[143610:]\n",
    "clf.fit(X_cv, y_cv)\n",
    "print(\"Area under ROC curve is\", roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
